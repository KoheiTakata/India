library(caret)
library(parallel)
library(doParallel)
library(randomForest)
prioritize(dplyr)
set.seed(02138)
reticulate::py_discover_config()
grid_default <- expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.3,
gamma = 0,
colsample_bytree = 1,
min_child_weight = 1,
subsample = 1)
#install.packages("randomForest")
#install.packages("caret")
#install.packages("parallel")
#install.packages("doParallel")
#install.packages("ggplot2")
no_cores <- detectCores() - 1
set.seed(02138)
MSE_table_RF     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i =1
MSE_table_XG     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i =1
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
holdout           <- data %>%
filter(District == District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
grid_default <- expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.3,
gamma = 0,
colsample_bytree = 1,
min_child_weight = 1,
subsample = 1)
train_control <- caret::trainControl(
method = "none",
verboseIter = FALSE, # no training log
allowParallel = TRUE) # FALSE for reproducible results )
y_train <- training$oos_g_5to14 %>%
as.matrix()
x_train <- training %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
## holdout
y_hold <- holdout$oos_g_5to14 %>%
as.matrix()
x_hold <- holdout %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
grid_default <- expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.3,
gamma = 0,
colsample_bytree = 1,
min_child_weight = 1,
subsample = 1)
train_control <- caret::trainControl(
method = "none",
verboseIter = FALSE, # no training log
allowParallel = TRUE) # FALSE for reproducible results )
i =1
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
holdout           <- data %>%
filter(District == District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
y_train <- training$oos_g_5to14 %>%
as.matrix()
x_train <- training %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
## holdout
y_hold <- holdout$oos_g_5to14 %>%
as.matrix()
x_hold <- holdout %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
cl <- makePSOCKcluster(no_cores)
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
grid_default <- expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.3,
gamma = 0,
colsample_bytree = 1,
min_child_weight = 1,
subsample = 1)
grid_default <- expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.3,
gamma = 0,
colsample_bytree = 1,
min_child_weight = 1,
subsample = 1)
train_control <- caret::trainControl(
method = "none",
verboseIter = FALSE, # no training log
allowParallel = TRUE) # FALSE for reproducible results )
xgb_base <- caret::train(
x = x_train,
y = y_train,
trControl = train_control,
tuneGrid = grid_default,
method = "xgbTree",
verbose = TRUE)
xgb_base <- caret::train(
x = x_train,
y = y_train,
trControl = train_control,
tuneGrid = grid_default,
method = "xgbTree",
verbose = TRUE)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("glmnet")
#install.packages("MLmetrics")
#install.packages("neuralnet")
#install.packages("keras")
#install.packages("mlbench")
#install.packages("magrittr")
#install.packages("tensorflow")
#install.packages("HDCI")
#install.packages("tidyverse")
#install.packages("sringr")
#install.packages(foreach)
#install.packages("needs")
library(foreach)
library(glmnet)
library(MLmetrics)
library(neuralnet)
library(keras)
library(mlbench)
library(magrittr)
library(tensorflow)
library(HDCI)
library(reticulate)
library(stringr)
library(parallel)
library(doParallel)
library(tidyverse)
library(needs)
library(caret)
library(parallel)
library(doParallel)
library(randomForest)
prioritize(dplyr)
set.seed(02138)
reticulate::py_discover_config()
#install.packages("randomForest")
#install.packages("caret")
#install.packages("parallel")
#install.packages("doParallel")
no_cores <- detectCores() - 1
set.seed(02138)
MSE_table_RF     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i =1
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
holdout           <- data %>%
filter(District == District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
cl <- makePSOCKcluster(no_cores)
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
model_RF <-train(oos_g_5to14~., data=training, method='rf', ntree = 5)
model_RF <-train(oos_g_5to14~., data=training, method='rf', ntree = 5)
stop.time<-proc.time()
run.time<-stop.time -start.time
print(run.time)
pred_RF           <- predict(model_RF, newdata=holdout)
MSE_table_RF[i,1] <- MSE(pred_RF, holdout$oos_g_5to14)
print(MSE_table_RF[i,1])
#model_RF          <- randomForest(oos_g_5to14~., data= training, subset = c(1:2000), importance = TRUE)
print(model_RF)
model_RF <-train(oos_g_5to14~., data=training, method='rf', ntree = 30)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("glmnet")
#install.packages("MLmetrics")
#install.packages("neuralnet")
#install.packages("keras")
#install.packages("mlbench")
#install.packages("magrittr")
#install.packages("tensorflow")
#install.packages("HDCI")
#install.packages("tidyverse")
#install.packages("sringr")
#install.packages(foreach)
library(foreach)
library(glmnet)
library(MLmetrics)
library(neuralnet)
library(keras)
library(mlbench)
library(magrittr)
library(tensorflow)
library(HDCI)
library(reticulate)
library(stringr)
library(dplyr)
reticulate::py_discover_config()
MSE_table_NN     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i = 4
## for loop
for(i in 1:14){
training   <- data %>%
filter(District != District_list[i])
holdout    <- data %>%
filter(District == District_list[i])
y_train <- training$oos_g_5to14 %>%
as.matrix()
x_train <- training %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
## holdout
y_hold <- holdout$oos_g_5to14 %>%
as.matrix()
x_hold <- holdout %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
m <- colMeans(x_train)
s <- apply(x_train, 2, sd)
x_train_std <- scale(x_train, center = m, scale = s)
x_hold_std  <- scale(x_hold,  center = m, scale = s)
## NN
model <- keras_model_sequential()
#model %>%
#       layer_dense(units = 5, activation = 'relu', input_shape = c(339)) %>%
#       layer_dense(units = 1)
model %>%
layer_dense(units = 10, activation = 'relu', input_shape = c(341)) %>%
layer_dropout(rate=0.50)  %>%
layer_dense(units = 5, activation = 'relu')  %>%
layer_dropout(rate=0.2)  %>%
layer_dense(units = 1)
model %>% compile(loss      = 'mse',
optimizer = 'rmsprop',
metrics   = 'mae')
mymodel <- model %>%
fit(x_train_std, y_train,
epochs = 50,
batch_size = 32,
validation_split = 0.2)
model %>%
evaluate(x_hold_std, y_hold)
pred <- model %>% predict(x_hold_std)
MSE_table_NN[i,1] <- mean((y_hold-pred)^2)
MSE_table_NN[i,1]
}
MSE_table_NN
stopCluster(cl)
MSE_table_NN     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i = 4
## for loop
for(i in 1:14){
training   <- data %>%
filter(District != District_list[i])
holdout    <- data %>%
filter(District == District_list[i])
y_train <- training$oos_g_5to14 %>%
as.matrix()
x_train <- training %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
## holdout
y_hold <- holdout$oos_g_5to14 %>%
as.matrix()
x_hold <- holdout %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
m <- colMeans(x_train)
s <- apply(x_train, 2, sd)
x_train_std <- scale(x_train, center = m, scale = s)
x_hold_std  <- scale(x_hold,  center = m, scale = s)
## NN
model <- keras_model_sequential()
#model %>%
#       layer_dense(units = 5, activation = 'relu', input_shape = c(339)) %>%
#       layer_dense(units = 1)
model %>%
layer_dense(units = 10, activation = 'relu', input_shape = c(341)) %>%
layer_dropout(rate=0.50)  %>%
layer_dense(units = 5, activation = 'relu')  %>%
layer_dropout(rate=0.2)  %>%
layer_dense(units = 1)
model %>% compile(loss      = 'mse',
optimizer = 'rmsprop',
metrics   = 'mae')
mymodel <- model %>%
fit(x_train_std, y_train,
epochs = 30,
batch_size = 32,
validation_split = 0.2)
model %>%
evaluate(x_hold_std, y_hold)
pred <- model %>% predict(x_hold_std)
MSE_table_NN[i,1] <- mean((y_hold-pred)^2)
MSE_table_NN[i,1]
}
MSE_table_NN[15,1]<- mean(MSE_table_NN[1:14,1])
MSE_table_NN
write.csv(MSE_table_NN, "result_NN.csv")
MSE_table_NN     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i = 4
## for loop
for(i in 1:14){
training   <- data %>%
filter(District != District_list[i])
holdout    <- data %>%
filter(District == District_list[i])
y_train <- training$oos_g_5to14 %>%
as.matrix()
x_train <- training %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
## holdout
y_hold <- holdout$oos_g_5to14 %>%
as.matrix()
x_hold <- holdout %>%
select(colnames(data)[11:ncol(data)]) %>%
as.matrix()
m <- colMeans(x_train)
s <- apply(x_train, 2, sd)
x_train_std <- scale(x_train, center = m, scale = s)
x_hold_std  <- scale(x_hold,  center = m, scale = s)
## NN
model <- keras_model_sequential()
#model %>%
#       layer_dense(units = 5, activation = 'relu', input_shape = c(339)) %>%
#       layer_dense(units = 1)
model %>%
layer_dense(units = 10, activation = 'relu', input_shape = c(341)) %>%
layer_dropout(rate=0.50)  %>%
layer_dense(units = 5, activation = 'relu')  %>%
layer_dropout(rate=0.2)  %>%
layer_dense(units = 1)
model %>% compile(loss      = 'mse',
optimizer = 'rmsprop',
metrics   = 'mae')
mymodel <- model %>%
fit(x_train_std, y_train,
epochs = 25,
batch_size = 32,
validation_split = 0.2)
model %>%
evaluate(x_hold_std, y_hold)
pred <- model %>% predict(x_hold_std)
MSE_table_NN[i,1] <- mean((y_hold-pred)^2)
MSE_table_NN[i,1]
}
MSE_table_NN[15,1]<- mean(MSE_table_NN[1:14,1])
MSE_table_NN
write.csv(MSE_table_NN, "result_NN.csv")
View(data)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("glmnet")
#install.packages("MLmetrics")
#install.packages("neuralnet")
#install.packages("keras")
#install.packages("mlbench")
#install.packages("magrittr")
#install.packages("tensorflow")
#install.packages("HDCI")
#install.packages("tidyverse")
#install.packages("sringr")
#install.packages(foreach)
#install.packages("needs")
library(foreach)
library(glmnet)
library(MLmetrics)
library(neuralnet)
library(keras)
library(mlbench)
library(magrittr)
library(tensorflow)
library(HDCI)
library(reticulate)
library(stringr)
library(parallel)
library(doParallel)
library(tidyverse)
library(needs)
library(caret)
library(parallel)
library(doParallel)
library(randomForest)
prioritize(dplyr)
set.seed(02138)
reticulate::py_discover_config()
#install.packages("randomForest")
#install.packages("caret")
#install.packages("parallel")
#install.packages("doParallel")
no_cores <- detectCores() - 1
set.seed(02138)
MSE_table_RF     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i =1
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
holdout           <- data %>%
filter(District == District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
model_RF <-train(oos_g_5to14~., data=training, method='rf', ntree = 30)
#model_RF          <- randomForest(oos_g_5to14~., data= training, subset = c(1:2000), importance = TRUE)
#print(model_RF)
stop.time<-proc.time()
run.time<-stop.time -start.time
print(run.time)
stopCluster(cl)
pred_RF           <- predict(model_RF, newdata=holdout)
MSE_table_RF[i,1] <- MSE(pred_RF, holdout$oos_g_5to14)
print(MSE_table_RF[i,1])
#install.packages("randomForest")
#install.packages("caret")
#install.packages("parallel")
#install.packages("doParallel")
no_cores <- detectCores() - 1
set.seed(02138)
MSE_table_RF     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i =1
for(i in 1:14){
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
holdout           <- data %>%
filter(District == District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
model_RF <-train(oos_g_5to14~., data=training, method='rf', ntree = 10)
#model_RF          <- randomForest(oos_g_5to14~., data= training, subset = c(1:2000), importance = TRUE)
#print(model_RF)
stop.time<-proc.time()
run.time<-stop.time -start.time
print(run.time)
stopCluster(cl)
pred_RF           <- predict(model_RF, newdata=holdout)
MSE_table_RF[i,1] <- MSE(pred_RF, holdout$oos_g_5to14)
print(MSE_table_RF[i,1])
}
plot(pred_RF, holdout$oos_g_5to14)
abline(0,1)
print(MSE_table_RF[i,1])
i =1
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
holdout           <- data %>%
filter(District == District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
registerDoParallel(cl)
model_RF <-train(oos_g_5to14~., data=training, method='rf', ntree = 10)
#model_RF          <- randomForest(oos_g_5to14~., data= training, subset = c(1:2000), importance = TRUE)
#print(model_RF)
stop.time<-proc.time()
run.time<-stop.time -start.time
print(run.time)
print(run.time)
stopCluster(cl)
pred_RF           <- predict(model_RF, newdata=holdout)
pred_RF           <- predict(model_RF, newdata=holdout)
MSE_table_RF[i,1] <- MSE(pred_RF, holdout$oos_g_5to14)
print(MSE_table_RF[i,1])
#install.packages("randomForest")
#install.packages("caret")
#install.packages("parallel")
#install.packages("doParallel")
no_cores <- detectCores() - 1
set.seed(02138)
MSE_table_RF     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
i =1
training          <- data %>%
filter(District != District_list[i]) %>%
select(colnames(data)[10: ncol(data)])
cl <- makePSOCKcluster(no_cores)
cl <- makePSOCKcluster(no_cores)
start.time<-proc.time()
registerDoParallel(cl)
tg <- data.frame(mtry = seq(2, 10, by = 2), )
pred_RF           <- predict(model_RF, newdata=holdout)
pred_RF           <- predict(model_RF, newdata=holdout)
MSE_table_RF[i,1] <- MSE(pred_RF, holdout$oos_g_5to14)
MSE_table_RF[i,1] <- MSE(pred_RF, holdout$oos_g_5to14)
print(MSE_table_RF[i,1])
tg <- data.frame(mtry = seq(2, 10, by = 2))
tc <- trainControl(method = "cv", number = 10)
model_RF <-train(oos_g_5to14~., data=training, method='rf', tuneGrid = tg)
model_RF <-train(oos_g_5to14~., data=training, method='rf', tuneGrid = tg)
