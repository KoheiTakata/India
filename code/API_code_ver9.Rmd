---
title: "API_209_Final"
author: "GoldenState Warriors"
date: "11/1/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include = TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stargazer)
library(glmnet)
library(MLmetrics)
library(mice)
library(readxl)
library(neuralnet)
library(keras)
library(mlbench)
library(magrittr)
library(tensorflow)
library(HDCI)


#install_tensorflow()
#install_tensorflow(version = "2.0.0")
```

## 1. Importing the data

```{r import data, include = TRUE}
ASER   <- read.csv("./input/data/aser_data.csv") %>% 
          select(-X) ## remove IDs
d2d    <- read.csv("./input/data/d2d_data.csv") %>% 
          select(-c(is_duplicate, X)) ## remove IDs
census <- read.csv("./input/data/dise_census_training.csv") %>% 
          select(-c(X, index, missing_census, match_dise_census,cluster_name_DISE, ## remove non-necessary cols
                  village_name_CENSUS)) %>% 
          mutate(NAs = rowSums(is.na(.)))            ## col for counting NAs in a row

shrID  <- read.csv("./input/data/shrug_names.csv") 

data_list <-  readxl::read_xlsx("./input/data/data_dictionary.xlsx")
```

## 2. Descriptive Statistics for PSet


```{r descriptive, include = TRUE}
DES_OOSG <- d2d %>% 
            group_by(D2D_year) %>% 
            summarize(Mean      = mean(oos_g_5to14),
                      STD       = sd(oos_g_5to14),
                      "25th"    = quantile(oos_g_5to14,  probs = 0.25),
                      "Median"  = quantile(oos_g_5to14,  probs = 0.50),
                      "75th"    = quantile(oos_g_5to14,  probs = 0.75),
                      "90th"    = quantile(oos_g_5to14,  probs = 0.90),
                      N         = n())

OOSG_chart <- d2d %>% 
              mutate(year = factor(D2D_year))

chart1 <- ggplot(data = OOSG_chart, aes(x = oos_g_5to14, color=year, fill=year))+
          geom_histogram(alpha=0.5, position="identity", binwidth = 20)+
          scale_x_continuous(name   = "Number of out school girls in Village",
                             breaks = seq(0, 200, 20),
                             limits = c(0, 200)) +
          facet_wrap(~year)

chart2 <- ggplot(data = OOSG_chart, aes(x = oos_g_5to14, color=year, fill=year))+
          geom_histogram(aes(y = ..density..),alpha=0.5, position="identity", binwidth = 5)+
          scale_x_continuous(name  = "Number of out school girls in Village",
                            breaks = seq(0, 200, 20),
                            limits = c(0, 200)) +
          facet_wrap(~year)


DES_OOSG

chart2

chart3 <- boxplot(oos_g_5to14 ~ year, 
                  data   = OOSG_chart, 
                  main   = "Boxplots for each year",
                  xlab   = "Year", 
                  ylab   = "Number of out school girls in Village", 
                  col    = "orange", 
                  border = "brown",
                  ylim   = c(0, 400)) 

```


## 3. Additional Dataset
```{r additional data, include = TRUE}

shr_ID  <- shrID %>% 
           mutate(state_ID   = str_sub(shrid, start = 4, end = 5),
                  village_ID = str_sub(shrid, start = 7, end = 100)) 

DISE_ID <- census %>% 
           select(1:6, village_code_CENSUS, StateDistrictCode) %>% 
           mutate(state_ID = ifelse(nchar(StateDistrictCode) == 3,        # if 3 => "0X", if 4 => "XX"
                                    paste("0", str_sub(StateDistrictCode, 1, 1), sep = ""),
                                    str_sub(StateDistrictCode, 1, 2))) %>% 
           mutate(village_ID = str_sub(village_code_CENSUS, 6, 11)) %>% 
           filter(VillageCode %in% d2d$VillageCode) %>% 
           left_join(shr_ID, by = c("state_ID", "village_ID")) %>% 
           select(VillageCode, shrid)


#write.csv(DISE_ID, "DISE_ID.csv")

poverty    <- read.csv("./input/data/shrug_secc_poverty_rate.csv") %>% 
              select(shrid,    secc_pov_rate_rural) %>% 
              rename(poverty = secc_pov_rate_rural) %>% 
              left_join(DISE_ID, by = "shrid") %>% 
              select(VillageCode, poverty)

```

## 4. Merging the data
Looking at the ASER data, there should be 197 districts in India. But, in the d2d data, only 14 districts are included.  
In the problem setting, it seems only these 13 districts are in concern. Therefore, I aggregate the data for each village in these 13 districts only.

First, I aggregate the data for d2d and ASER.

```{r merge_data, include=TRUE}
census_2014_ori <- census %>%                                                                 
                   select(VillageCode, ends_with("1314")) %>%                                ## extract DISE data for 2013/14
                   rename_at(vars(ends_with("1314")), funs(str_replace(., "1314", ""))) %>%  ## remove last digit of 1314
                   rename_at(vars(ends_with("_"))   , funs(str_replace(., "_", ""))) %>%     ## remove last _ for "village_"
                   mutate(DISE_year = 2014) %>%                                              ## record DISE base year
                   relocate(DISE_year)                                                       ## move the DISE_year to the first col
              
census_2017_ori <- census %>% 
                   select(VillageCode, ends_with("1617")) %>% 
                   rename_at(vars(ends_with("1617")), funs(str_replace(., "1617", ""))) %>% 
                   rename_at(vars(ends_with("_"))   , funs(str_replace(., "_", ""))) %>% 
                   mutate(DISE_year = 2017) %>% 
                   relocate(DISE_year)

census_2018_ori <- census %>% 
                   select(VillageCode, ends_with("1718")) %>% 
                   rename_at(vars(ends_with("1718")), funs(str_replace(., "1718", ""))) %>% 
                   rename_at(vars(ends_with("_"))   , funs(str_replace(., "_", ""))) %>% 
                   mutate(DISE_year = 2018) %>% 
                   relocate(DISE_year)

census_DISE <- census %>% 
               select(VillageCode, ends_with("c11"), NAs) %>%                           ## extract cols for census data
               rename_at(vars(ends_with("c11")), funs(str_replace(., "c11", "")))       ## remove last c11



```

```{r data_imputation_census, include=TRUE}
## Imputation for Census data
imp_census <- function(x, y){
                for(i in 1:nrow(x)){
                  for(j in 1:ncol(x)){
                    if(is.na(x[i,j])== TRUE){
                      x[i,j]= y[i,j]
                    }  
                  }
                }
              return(x)
              }

census_2018 <- imp_census(census_2018_ori, census_2017_ori) %>%   ## missing value for 2018 <- imputed by 2017
               imp_census(census_2014_ori)                        ## if still missing       <- imputed by 2014
               
census_2017 <- imp_census(census_2017_ori, census_2018_ori) %>% 
               imp_census(census_2014_ori)


data_temp <- d2d %>% 
             left_join(ASER, by = "District")                     ## merge ASER into d2d

data_2016 <- data_temp %>% 
             filter(D2D_year == 2016) %>%                         ## filter d2d 2016 data
             left_join(census_2017, by = "VillageCode")           ## merge with DISE 2017 year (closest year)

data_2017 <- data_temp %>% 
             filter(D2D_year == 2017) %>% 
             left_join(census_2017, by = "VillageCode")


data_2019 <- data_temp %>% 
             filter(D2D_year == 2019) %>% 
             left_join(census_2017, by = "VillageCode")

data_2020 <- data_temp %>% 
             filter(D2D_year == 2020) %>% 
             left_join(census_2017, by = "VillageCode")

data_ori  <- data_2016 %>%                                  ## merge all filtered data for d2d and DISE
             bind_rows(data_2017) %>% 
             bind_rows(data_2019) %>% 
             bind_rows(data_2020) %>% 
             left_join(census_DISE, by = "VillageCode") %>% ## merge census data
             left_join(poverty,     by = "VillageCode")

```

```{r data_aggregate, include = FALSE}
data_temp <- d2d %>% 
             left_join(ASER, by = "District")             ## merge ASER into d2d

data_2016 <- data_temp %>% 
             filter(D2D_year == 2016) %>%                 ## filter d2d 2016 data
             left_join(census_2017, by = "VillageCode")   ## merge with DISE 2017 year (closest year)

data_2017 <- data_temp %>% 
             filter(D2D_year == 2017) %>% 
             left_join(census_2017, by = "VillageCode")


data_2019 <- data_temp %>% 
             filter(D2D_year == 2019) %>% 
             left_join(census_2017, by = "VillageCode")

data_2020 <- data_temp %>% 
             filter(D2D_year == 2020) %>% 
             left_join(census_2017, by = "VillageCode")

data_ori  <- data_2016 %>%                                 ## merge all filtered data for d2d and DISE
             bind_rows(data_2017) %>% 
             bind_rows(data_2019) %>% 
             bind_rows(data_2020) %>% 
             left_join(census_DISE, by = "VillageCode") %>% ## merge census data
             left_join(poverty,     by = "VillageCode")

```

```{r data_imputation_all, include= TRUE}

##dont try to run: it takes 6 hours


data_unimp <- data_ori %>% 
              select(VillageCode:D2D_year, DISE_year, oos_g_5to14, ASER, village:poverty) %>% 
              mutate(District = as.factor(District))

init <- mice(data_unimp, maxit = 0)

predM = init$predictorMatrix

predM[, c(1,2, 7, 8, 9, 10)] = 0

set.seed(02138)
imputed = mice(data_unimp, method= "cart", predictorMatrix=predM, m= 5, maxit = 30) 
data <- complete(imputed)

#write.csv(data, "data.csv")
```

```{r data_import, include = TRUE}
data <- read.csv("data.csv") %>% 
        select(-X)

```

## 5. Regression
```{r regression_function, include=TRUE}
District_list  <- unique(data$District)
MSE_table      <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1)

model          <- lm(oos_g_5to14 ~ ASER + numschools, data = data)

MSE_func <- function(model, data){
            for(i in 1:14){
            training       <- data %>% 
                              filter(District != District_list[i])
            holdout        <- data %>% 
                              filter(District == District_list[i])
            
            model_1        <- lm(model$call[2], data = training)
            
            MSE_table[i,1] <- mean((predict(model_1, newdata = holdout) - holdout$oos_g_5to14)^2, na.rm = TRUE)
            }
            
            MSE_table[15,1]<- mean(MSE_table[1:14,1])
            return(list(result <- summary(model_1), MSE <- MSE_table))
}

```




```{r long, include=TRUE}
f_long_rhs  <- str_c(colnames(data)[10:ncol(data)], collapse = " + ")
f_long_c    <- as.formula(str_c("oos_g_5to14 ~ ", f_long_rhs))

model_long  <- lm(f_long_c, data = data)
result_long <- MSE_func(model_long, data)

result_long[[2]]
write.csv(result_long[[2]], "result_long.csv")
```

```{r lasso, include=TRUE}

MSE_table     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing

## for loop
for(i in 1:14){
  training   <- data %>% 
                filter(District != District_list[i])
  holdout    <- data %>% 
                filter(District == District_list[i])
  
  ## training
  y_train <- training$oos_g_5to14 %>% 
             as.matrix()
  x_train <- training %>% 
             select(colnames(data)[11:ncol(data)]) %>% 
             as.matrix()
  
  ## holdout
  y_hold <- holdout$oos_g_5to14 %>% 
            as.matrix()
  
  x_hold <- holdout %>% 
            select(colnames(data)[11:ncol(data)]) %>% 
            as.matrix()
  
  ## LASSO
  cv_model <- cv.glmnet(x = x_train, y = y_train)
  #summary(cv_model)
  #plot(cv_model)
  #coef_lasso <- enframe(coef(cv_model, s="lambda.min")[,1])
  
  MSE_table[i,1] <- MSE(predict(cv_model, newx = x_hold, s="lambda.min"), y_hold)
}
 MSE_table[15,1]<- mean(MSE_table[1:14,1])
 MSE_table
 
 #write.csv(MSE_table, "LASSO.csv")
```

```{r LMG, include = TRUE}
cv_model

```

```{r regression_2, include= TRUE}
## put all variables you want
model <- lm(oos_g_5to14 ~ ASER + numschools + tot_g , data = data)

model_1 <- MSE_func(model, data)

model_1

model   <- lm(oos_g_5to14 ~ ASER + numschools + tot_g + kitshed_avail, data = data)

model_2 <- MSE_func(model, data)

model_2

```

```{r Random_Forest, include=TRUE}
#install.packages("randomForest")
library(randomForest)
set.seed(02138)

MSE_table     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing


for(i in 1:14){
  training          <- data %>% 
                       filter(District != District_list[i])
  holdout           <- data %>% 
                       filter(District == District_list[i])

  model_RF          <- randomForest(oos_g_5to14~., data= training, subset = c(1:1000), importance = TRUE)

  pred_RF           <- predict(model_RF, newdata=holdout)
  MSE_table_RF[i,1] <- mean((pred_RF-holdout$oos_g_5to14)^2)
}

plot(pred_RF, holdout$oos_g_5to14)
abline(0,1)
```

```{r NN, include=TRUE}
MSE_table_NN     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing

i = 1
## for loop
for(i in 1:14){
  training   <- data %>% 
                filter(District != District_list[i]) %>% 
                select(!c(1:9))
  holdout    <- data %>% 
                filter(District == District_list[i]) %>% 
                select(!c(1:9))
  #m <- colMeans(training)
  #s <- apply(training, 2, sd)
  #training_std <- scale(training, center = m, scale = s)
  #holdout_std  <- scale(holdout,  center = m, scale = s)
  
  ## NN
  nn <- neuralnet(f_long_c, data = training, hidden = 3)
  #predict = (compute(nn, holdout_std)+m[1])*s[1]
  predict = compute(nn, holdout)
  #plot(nn)


  MSE_table_NN[i,1] <- MSE(predict, holdout$oos_g_5to14)
  MSE_table_NN[i,1]
}
 MSE_table_NN[15,1]<- mean(MSE_table[1:14,1])
 MSE_table_NN



```


```{r Udaipur, include = TRUE}

  training   <- data %>% 
                filter(District != "UDAIPUR")
  holdout    <- data %>% 
                filter(District == "UDAIPUR")
  
  ## training
  y_train <- training$oos_g_5to14 %>% 
             as.matrix()
  x_train <- training %>% 
             select(colnames(data)[11:ncol(data)]) %>% 
             as.matrix()
  
  ## holdout
  y_hold <- holdout$oos_g_5to14 %>% 
            as.matrix()
  
  x_hold <- holdout %>% 
            select(colnames(data)[11:ncol(data)]) %>% 
            as.matrix()
  
  ## LASSO
  cv_model <- cv.glmnet(x = x_train, y = y_train)
  summary(cv_model)
  #plot(cv_model)
  coef_lasso <- enframe(coef(cv_model, s="lambda.min")[,1]) %>% 
                filter(value != 0)
  
oosg_udai <- predict(cv_model, newx = x_hold, s="lambda.min")

plot(x = oosg_udai, y = holdout$oos_g_5to14, xlim = c(0, 150), ylim = c(0, 150))


#write.csv(oosg_udai, "oosg_udai.csv")



```

```{r confidence_interval, include=TRUE}
B <- 500
pred <- array(data = NA, dim = c(nrow(holdout),B))
for (i in 1:B) {
  boot <- sample(nrow(x_train), nrow(x_train), replace = TRUE)
  
  x_train_boot <- x_train[boot,]
  y_train_boot <- y_train[boot,]
  
  cv_model  <- cv.glmnet(x = x_train_boot, y = y_train_boot)
  pred[,i]  <- predict(cv_model, newx = x_hold, s="lambda.min")
  print(i)
}

#write.csv(pred, "pred.csv")
CI <- pred %>% 
      t() %>% 
      as.data.frame() %>% 
      summarize(across(.cols = everything(), list( ~ quantile(., c(0.025, 0.975))))) %>% 
      t() %>% 
      as.data.frame() %>% 
      cbind(oosg_udai) %>%
      cbind(holdout$Block) %>% 
      cbind(holdout$District) %>%
      select( c(4, 5, 3, 1, 2)) %>% 
       `colnames<-`(c("lower", "upper", "mean", "Block", "District"))
#write.csv(CI, "udai_CI.csv")


```

# 6. regression in ratio
```{r data_raio, include = FALSE}
num_unit <- unique(data_list$Unit)[c(3, 4, 5, 11)] ## picking up level variables

num_list <- data_list %>% 
            filter(`Change during reclean (24 Apr 2020)?` != "Dropped") %>% 
            mutate(Variable = ifelse(Variable == "main_cl_mc", "main_cl_m", Variable)) %>% 
            filter(Unit %in% num_unit) %>% 
            select(Variable) %>% 
            filter(Variable != "tch_male")


data_ratio <- data %>% 
              mutate(oos_g_5to14 = oos_g_5to14 / tot_p) %>% 
              rename(oosg_ratio = oos_g_5to14) %>% 
              mutate_at(.vars = vars(num_list$Variable),
                        .funs = list(ratio =  ~. /tot_p)) %>% 
              select(-num_list$Variable)
```

```{r regression_ratio, include = FALSE}
District_list  <- unique(data_ratio$District)
MSE_table      <- matrix(NA, nrow = length(unique(data_ratio$District)) + 1, ncol = 1)

model          <- lm(oosg_ratio ~ ASER + numschools_ratio, data = data_ratio)

MSE_ratio_func <- function(model, data_ratio, data){
                  for(i in 1:14){
                  training       <- data_ratio %>% 
                                    filter(District != District_list[i])
                  holdout        <- data_ratio %>% 
                                    filter(District == District_list[i])
                  
                  answer         <- data %>% 
                                    filter(District == District_list[i])
                  
                  model_1        <- lm(model$call[2], data = training)
                  
                  MSE_table[i,1] <- mean((predict(model_1, newdata = holdout)*holdout$tot_p - 
                                          answer$oos_g_5to14)^2, na.rm = TRUE)
                  }
                  
                  MSE_table[15,1]<- mean(MSE_table[1:14,1])
                  return(list(result <- summary(model_1), MSE <- MSE_table))
}

```

```{r long, include = TRUE}
f_long_rhs        <- str_c(colnames(data_ratio)[10:ncol(data_ratio)], collapse = " + ")
f_long_c          <- as.formula(str_c("oosg_ratio ~ ", f_long_rhs))

model_long        <- lm(f_long_c, data = data_ratio)
result_ratio_long <- MSE_ratio_func(model_long, data_ratio, data)

result_ratio_long[[2]]
#write.csv(result_long[[2]], "result_long.csv")

```

