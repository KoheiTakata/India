
```{r setup, include = TRUE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("glmnet")
#install.packages("MLmetrics")
#install.packages("neuralnet")
#install.packages("keras")
#install.packages("mlbench")
#install.packages("magrittr")
#install.packages("tensorflow")
#install.packages("HDCI")


library(tidyverse)
library(glmnet)
library(MLmetrics)
library(neuralnet)
library(keras)
library(mlbench)
library(magrittr)
library(tensorflow)
library(HDCI)


#install_tensorflow()
#install_tensorflow(version = "2.0.0")
```


```{r data_import, include = TRUE}
data <- read.csv("https://github.com/KoheiTakata/India/raw/main/data/data.csv") %>% 
        select(-X)

```

## 5. Regression
```{r regression_function, include=TRUE}
District_list  <- unique(data$District)
MSE_table      <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1)

model          <- lm(oos_g_5to14 ~ ASER + numschools, data = data)

MSE_func <- function(model, data){
            for(i in 1:14){
            training       <- data %>% 
                              filter(District != District_list[i])
            holdout        <- data %>% 
                              filter(District == District_list[i])
            
            model_1        <- lm(model$call[2], data = training)
            
            MSE_table[i,1] <- mean((predict(model_1, newdata = holdout) - holdout$oos_g_5to14)^2, na.rm = TRUE)
            }
            
            MSE_table[15,1]<- mean(MSE_table[1:14,1])
            return(list(result <- summary(model_1), MSE <- MSE_table))
}

```




```{r long, include=TRUE}
f_long_rhs  <- str_c(colnames(data)[11:ncol(data)], collapse = " + ")
f_long_c    <- as.formula(str_c("oos_g_5to14 ~ ", f_long_rhs))

model_long  <- lm(f_long_c, data = data)
result_long <- MSE_func(model_long, data)

result_long[[2]]
write.csv(result_long[[2]], "result_long.csv")
```

```{r lasso, include=TRUE}

MSE_table     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing

## for loop
for(i in 1:14){
  training   <- data %>% 
                filter(District != District_list[i])
  holdout    <- data %>% 
                filter(District == District_list[i])
  
  ## training
  y_train <- training$oos_g_5to14 %>% 
             as.matrix()
  x_train <- training %>% 
             select(colnames(data)[11:ncol(data)]) %>% 
             as.matrix()
  
  ## holdout
  y_hold <- holdout$oos_g_5to14 %>% 
            as.matrix()
  
  x_hold <- holdout %>% 
            select(colnames(data)[11:ncol(data)]) %>% 
            as.matrix()
  
  ## LASSO
  cv_model <- cv.glmnet(x = x_train, y = y_train)
  #summary(cv_model)
  #plot(cv_model)
  #coef_lasso <- enframe(coef(cv_model, s="lambda.min")[,1])
  
  MSE_table[i,1] <- MSE(predict(cv_model, newx = x_hold, s="lambda.min"), y_hold)
}
 MSE_table[15,1]<- mean(MSE_table[1:14,1])
 MSE_table
 
 #write.csv(MSE_table, "LASSO.csv")
```

```{r LMG, include = TRUE}
cv_model

```

```{r regression_2, include= TRUE}
## put all variables you want
model <- lm(oos_g_5to14 ~ ASER + numschools + tot_g , data = data)

model_1 <- MSE_func(model, data)

model_1

model   <- lm(oos_g_5to14 ~ ASER + numschools + tot_g + kitshed_avail, data = data)

model_2 <- MSE_func(model, data)

model_2

```

```{r Random_Forest, include=TRUE}
#install.packages("randomForest")
#install.packages("caret")
install.packages("doParallel")
library(doParallel)
library(caret)
library(randomForest)
set.seed(02138)

MSE_table     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing
cl<-makePSOCKcluster(8)

i =1
for(i in 1:14){
  training          <- data %>% 
                       filter(District != District_list[i])
  holdout           <- data %>% 
                       filter(District == District_list[i])
  
  registerDoParallel(cl)

  model_RF <-train(oos_g_5to14~., data=training, method='rf')

  #model_RF          <- randomForest(oos_g_5to14~., data= training, importance = TRUE)

  pred_RF           <- predict(model_RF, newdata=holdout)
  MSE_table_RF[i,1] <- mean((pred_RF-holdout$oos_g_5to14)^2)
}

plot(pred_RF, holdout$oos_g_5to14)
abline(0,1)
```

```{r NN, include=TRUE}
MSE_table_NN     <- matrix(NA, nrow = length(unique(data$District)) + 1, ncol = 1) ## spacing

i = 4
## for loop
for(i in 1:14){
  training   <- data %>% 
                filter(District != District_list[i])
  
  holdout    <- data %>% 
                filter(District == District_list[i]) 
  
  y_train <- training$oos_g_5to14 %>% 
             as.matrix()
  
  x_train <- training %>% 
             select(colnames(data)[11:ncol(data)]) %>% 
             as.matrix()
  
  ## holdout
  y_hold <- holdout$oos_g_5to14 %>% 
            as.matrix()
  
  x_hold <- holdout %>% 
            select(colnames(data)[11:ncol(data)]) %>% 
            as.matrix()
  
  
  m <- colMeans(x_train)
  s <- apply(x_train, 2, sd)
  x_train_std <- scale(x_train, center = m, scale = s)
  x_hold_std  <- scale(x_hold,  center = m, scale = s)
  
  ## NN
  model <- keras_model_sequential()
  #model %>%
  #       layer_dense(units = 5, activation = 'relu', input_shape = c(339)) %>%
  #       layer_dense(units = 1)
  model %>%
        layer_dense(units = 10, activation = 'relu', input_shape = c(339)) %>%
        layer_dropout(rate=0.55)  %>%
        layer_dense(units = 5, activation = 'relu')  %>%
        layer_dropout(rate=0.2)  %>%
         layer_dense(units = 1)
  
  model %>% compile(loss      = 'mse',
                    optimizer = 'rmsprop', 
                    metrics   = 'mae') 
  
  
  mymodel <- model %>%          
              fit(x_train_std, y_train,
                  epochs = 100,
                  batch_size = 32,
                  validation_split = 0.2)
  
  model %>% evaluate(x_hold_std, y_hold)
  pred <- model %>% predict(x_hold_std)
 
  MSE_table_NN[i,1] <- mean((y_hold-pred)^2) 

  MSE_table_NN[i,1]
}
 MSE_table_NN[15,1]<- mean(MSE_table_NN[1:14,1])
 MSE_table_NN



```


```{r Udaipur, include = TRUE}

  training   <- data %>% 
                filter(District != "UDAIPUR")
  holdout    <- data %>% 
                filter(District == "UDAIPUR")
  
  ## training
  y_train <- training$oos_g_5to14 %>% 
             as.matrix()
  x_train <- training %>% 
             select(colnames(data)[11:ncol(data)]) %>% 
             as.matrix()
  
  ## holdout
  y_hold <- holdout$oos_g_5to14 %>% 
            as.matrix()
  
  x_hold <- holdout %>% 
            select(colnames(data)[11:ncol(data)]) %>% 
            as.matrix()
  
  ## LASSO
  cv_model <- cv.glmnet(x = x_train, y = y_train)
  summary(cv_model)
  #plot(cv_model)
  coef_lasso <- enframe(coef(cv_model, s="lambda.min")[,1]) %>% 
                filter(value != 0)
  
oosg_udai <- predict(cv_model, newx = x_hold, s="lambda.min")

plot(x = oosg_udai, y = holdout$oos_g_5to14, xlim = c(0, 150), ylim = c(0, 150))


#write.csv(oosg_udai, "oosg_udai.csv")



```

```{r confidence_interval, include=TRUE}
B <- 500
pred <- array(data = NA, dim = c(nrow(holdout),B))
for (i in 1:B) {
  boot <- sample(nrow(x_train), nrow(x_train), replace = TRUE)
  
  x_train_boot <- x_train[boot,]
  y_train_boot <- y_train[boot,]
  
  cv_model  <- cv.glmnet(x = x_train_boot, y = y_train_boot)
  pred[,i]  <- predict(cv_model, newx = x_hold, s="lambda.min")
  print(i)
}

#write.csv(pred, "pred.csv")
CI <- pred %>% 
      t() %>% 
      as.data.frame() %>% 
      summarize(across(.cols = everything(), list( ~ quantile(., c(0.025, 0.975))))) %>% 
      t() %>% 
      as.data.frame() %>% 
      cbind(oosg_udai) %>%
      cbind(holdout$Block) %>% 
      cbind(holdout$District) %>%
      select( c(4, 5, 3, 1, 2)) %>% 
       `colnames<-`(c("lower", "upper", "mean", "Block", "District"))
#write.csv(CI, "udai_CI.csv")


```

# 6. regression in ratio
```{r data_raio, include = FALSE}
num_unit <- unique(data_list$Unit)[c(3, 4, 5, 11)] ## picking up level variables

num_list <- data_list %>% 
            filter(`Change during reclean (24 Apr 2020)?` != "Dropped") %>% 
            mutate(Variable = ifelse(Variable == "main_cl_mc", "main_cl_m", Variable)) %>% 
            filter(Unit %in% num_unit) %>% 
            select(Variable) %>% 
            filter(Variable != "tch_male")


data_ratio <- data %>% 
              mutate(oos_g_5to14 = oos_g_5to14 / tot_p) %>% 
              rename(oosg_ratio = oos_g_5to14) %>% 
              mutate_at(.vars = vars(num_list$Variable),
                        .funs = list(ratio =  ~. /tot_p)) %>% 
              select(-num_list$Variable)
```

```{r regression_ratio, include = FALSE}
District_list  <- unique(data_ratio$District)
MSE_table      <- matrix(NA, nrow = length(unique(data_ratio$District)) + 1, ncol = 1)

model          <- lm(oosg_ratio ~ ASER + numschools_ratio, data = data_ratio)

MSE_ratio_func <- function(model, data_ratio, data){
                  for(i in 1:14){
                  training       <- data_ratio %>% 
                                    filter(District != District_list[i])
                  holdout        <- data_ratio %>% 
                                    filter(District == District_list[i])
                  
                  answer         <- data %>% 
                                    filter(District == District_list[i])
                  
                  model_1        <- lm(model$call[2], data = training)
                  
                  MSE_table[i,1] <- mean((predict(model_1, newdata = holdout)*holdout$tot_p - 
                                          answer$oos_g_5to14)^2, na.rm = TRUE)
                  }
                  
                  MSE_table[15,1]<- mean(MSE_table[1:14,1])
                  return(list(result <- summary(model_1), MSE <- MSE_table))
}

```

```{r long, include = TRUE}
f_long_rhs        <- str_c(colnames(data_ratio)[10:ncol(data_ratio)], collapse = " + ")
f_long_c          <- as.formula(str_c("oosg_ratio ~ ", f_long_rhs))

model_long        <- lm(f_long_c, data = data_ratio)
result_ratio_long <- MSE_ratio_func(model_long, data_ratio, data)

result_ratio_long[[2]]
#write.csv(result_long[[2]], "result_long.csv")

```
